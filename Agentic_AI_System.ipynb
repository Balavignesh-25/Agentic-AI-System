{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balavignesh-25/Agentic-AI-System/blob/main/Agentic_AI_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2515f58",
      "metadata": {
        "id": "c2515f58"
      },
      "source": [
        "# üß† FINAL Agentic AI Demo (Dynamic Tools + Guardrails)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "392c6c5e",
      "metadata": {
        "id": "392c6c5e"
      },
      "source": [
        "## 1Ô∏è‚É£ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92e903bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92e903bf",
        "outputId": "6705eb85-b283-49b1-e5da-74608edc5f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.2.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.6.8)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
            "Downloading langchain_groq-1.1.2-py3-none-any.whl (19 kB)\n",
            "Downloading langchain_core-1.2.9-py3-none-any.whl (496 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m496.3/496.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-core, langchain-groq\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.2.8\n",
            "    Uninstalling langchain-core-1.2.8:\n",
            "      Successfully uninstalled langchain-core-1.2.8\n",
            "Successfully installed groq-0.37.1 langchain-core-1.2.9 langchain-groq-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-groq langchain-core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "271a3f83",
      "metadata": {
        "id": "271a3f83"
      },
      "source": [
        "## 2Ô∏è‚É£ Configure API Key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False"
      ],
      "metadata": {
        "id": "RlTMR8zVDIe4"
      },
      "id": "RlTMR8zVDIe4",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "def get_secret(key_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Securely fetch secrets from Colab userdata or environment variables.\n",
        "\n",
        "    This function is crucial for managing sensitive information like API keys.\n",
        "    It prioritizes Google Colab's built-in 'userdata' for security,\n",
        "    then falls back to environment variables for local development.\n",
        "    \"\"\"\n",
        "    # Check if the code is currently running within a Google Colab environment.\n",
        "    # This helps in adapting how secrets are accessed.\n",
        "    if IN_COLAB:\n",
        "        # In Colab, secrets are managed securely via the 'userdata' interface.\n",
        "        # This prevents API keys from being directly exposed in the notebook or version control.\n",
        "        return userdata.get(key_name)\n",
        "    # If not in Colab (e.g., running locally or on another cloud platform),\n",
        "    # attempt to retrieve the secret from system environment variables.\n",
        "    # This provides flexibility for deployment outside of Colab.\n",
        "    return os.getenv(key_name)\n",
        "\n",
        "# Retrieve the Groq API key using the `get_secret` function.\n",
        "# The key named 'GROQ_API_KEY' is expected to be configured in Colab secrets or as an environment variable.\n",
        "GROQ_API_KEY = get_secret(\"GROQ_API_KEY\")\n",
        "\n",
        "# Perform a critical validation step: check if the API key was successfully loaded.\n",
        "# Without a valid API key, the LLM interactions will fail, so this check is essential.\n",
        "if not GROQ_API_KEY:\n",
        "    # If the key is missing, raise an error with clear instructions.\n",
        "    # This guides the user on how to correctly set up their API key.\n",
        "    raise EnvironmentError(\n",
        "        \"‚ùå API Key missing!\\n\"\n",
        "        \"‚Ä¢ In Colab ‚Üí Add it in Secrets and restart runtime\\n\"\n",
        "        \"‚Ä¢ Locally ‚Üí Export them as environment variables\"\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ API key loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur2pVe2CDPG6",
        "outputId": "b8f46507-dcce-42b6-d291-a541d08772cd"
      },
      "id": "ur2pVe2CDPG6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API key loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f201a2",
      "metadata": {
        "id": "97f201a2"
      },
      "source": [
        "## 3Ô∏è‚É£ Initialize LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bc854b7b",
      "metadata": {
        "id": "bc854b7b"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import tool\n",
        "import json\n",
        "\n",
        "llm = ChatGroq(\n",
        "    api_key=GROQ_API_KEY,\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def safe_json_parse(text: str, fallback: dict):\n",
        "    \"\"\"\n",
        "    Safely extract and parse JSON from LLM output.\n",
        "\n",
        "    LLMs sometimes produce text that isn't perfectly clean JSON.\n",
        "    This function tries to be robust by first attempting direct parsing,\n",
        "    and then by trying to extract a JSON-like substring.\n",
        "    \"\"\"\n",
        "    # If the input text is empty or contains only whitespace, it cannot be valid JSON.\n",
        "    # In such cases, we immediately return a predefined 'fallback' dictionary.\n",
        "    if not text or not text.strip():\n",
        "        return fallback\n",
        "\n",
        "    # First attempt: Try to parse the entire input `text` as a direct JSON string.\n",
        "    # This is the most straightforward and efficient method if the LLM output is clean.\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        # If direct parsing fails (e.g., due to extra text around the JSON or malformed JSON),\n",
        "        # we don't return an error yet, but proceed to a more lenient extraction method.\n",
        "        pass # If direct parse fails, try extracting a JSON block\n",
        "\n",
        "    # Second attempt: If direct parsing failed, try to find a JSON object embedded within the text.\n",
        "    # This uses a regular expression to locate the first `{...}` block that looks like a JSON object.\n",
        "    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
        "    if match:\n",
        "        try:\n",
        "            # If a potential JSON block is found, try parsing just that extracted substring.\n",
        "            # The `re.DOTALL` flag allows '.' to match newlines, important for multi-line JSON.\n",
        "            return json.loads(match.group())\n",
        "        except json.JSONDecodeError:\n",
        "            # If parsing the extracted block also fails, it means even the embedded part is malformed.\n",
        "            # We then fall through to return the fallback.\n",
        "            pass # If parsing the extracted block fails, return fallback\n",
        "\n",
        "    # If both direct parsing and embedded JSON extraction attempts fail,\n",
        "    # return the 'fallback' dictionary to ensure the program doesn't crash\n",
        "    # and has a predictable default value to work with.\n",
        "    return fallback"
      ],
      "metadata": {
        "id": "MjZdNCq3o_KZ"
      },
      "id": "MjZdNCq3o_KZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2cba269d",
      "metadata": {
        "id": "2cba269d"
      },
      "source": [
        "## 4Ô∏è‚É£ Guardrails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "940ae38f",
      "metadata": {
        "id": "940ae38f"
      },
      "outputs": [],
      "source": [
        "\n",
        "HIGH_RISK_TOPICS = [\n",
        "    \"stock price\",\n",
        "    \"share price\",\n",
        "    \"predict\",\n",
        "    \"prediction\",\n",
        "    \"after 1 hour\",\n",
        "    \"next hour\"\n",
        "]\n",
        "\n",
        "def guardrail_check(goal: str):\n",
        "    \"\"\"\n",
        "    Checks the user's input 'goal' against a list of high-risk topics.\n",
        "\n",
        "    This function acts as a safety mechanism (guardrail) to prevent the AI\n",
        "    from engaging in tasks that are deemed unsafe, unethical, or unreliable,\n",
        "    such as making financial predictions.\n",
        "    \"\"\"\n",
        "    # Iterate through each predefined high-risk topic.\n",
        "    # This loop systematically checks if any prohibited phrase is present in the user's request.\n",
        "    for topic in HIGH_RISK_TOPICS:\n",
        "        # Convert both the topic and the user's goal to lowercase for case-insensitive matching.\n",
        "        # This ensures that variations like 'Stock Price' or 'stock price' are caught.\n",
        "        if topic in goal.lower():\n",
        "            # If a high-risk topic is found, immediately block the request.\n",
        "            # Return a dictionary indicating it's blocked, along with a clear reason\n",
        "            # and suggesting safer, alternative queries.\n",
        "            return {\n",
        "                \"blocked\": True,\n",
        "                \"reason\": \"Financial market prediction is unreliable and unsafe\",\n",
        "                \"safe_alternatives\": [\n",
        "                    \"Explain how stock prices generally work\",\n",
        "                    \"Discuss investment risk factors\",\n",
        "                    \"Show historical trends\"\n",
        "                ]\n",
        "            }\n",
        "    # If the loop completes without finding any high-risk topics,\n",
        "    # the request is considered safe and not blocked.\n",
        "    return {\"blocked\": False}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df9e0a24"
      },
      "source": [
        "PII_KEYWORDS = [\n",
        "    \"name\",\n",
        "    \"email\",\n",
        "    \"phone\",\n",
        "    \"ssn\",\n",
        "    \"social security number\",\n",
        "    \"address\",\n",
        "    \"date of birth\",\n",
        "    \"credit card\",\n",
        "    \"account number\"\n",
        "]\n",
        "\n",
        "def pii_filter(text: str):\n",
        "    \"\"\"\n",
        "    Filters input text for Personally Identifiable Information (PII) keywords.\n",
        "\n",
        "    This function serves as a guardrail to protect user privacy by detecting\n",
        "    and flagging common PII terms in the input, preventing the AI from processing\n",
        "    or generating sensitive data inadvertently.\n",
        "    \"\"\"\n",
        "    # Loop through each keyword defined in the PII_KEYWORDS list.\n",
        "    # This allows for a comprehensive check against multiple types of personal information.\n",
        "    for keyword in PII_KEYWORDS:\n",
        "        # Convert the input `text` to lowercase to ensure the PII check is not case-sensitive.\n",
        "        # This way, 'Name', 'name', and 'NAME' are all detected.\n",
        "        if keyword in text.lower():\n",
        "            # If a PII keyword is found, the function immediately returns a 'blocked' status.\n",
        "            # It provides the specific keyword detected as the reason and suggests an action\n",
        "            # to the user, like redacting or sanitizing the input.\n",
        "            return {\n",
        "                \"blocked\": True,\n",
        "                \"reason\": f\"Potential PII detected: '{keyword}'\",\n",
        "                \"action\": \"Redact or sanitize input\"\n",
        "            }\n",
        "    # If the loop finishes without finding any of the specified PII keywords,\n",
        "    # the function returns 'blocked': False, indicating that no PII was detected.\n",
        "    return {\"blocked\": False}"
      ],
      "id": "df9e0a24",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9856bcb0"
      },
      "source": [
        "### How to use the PII filter:\n",
        "\n",
        "Now you can integrate `pii_filter` into your `agentic_ai_system` or use it independently. Here's an example of how you can test it:"
      ],
      "id": "9856bcb0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d404cba5",
        "outputId": "faf37020-bfb8-48b7-c0a6-ffcb6ea6bb7d"
      },
      "source": [
        "print(pii_filter(\"My name is John Doe and my email is john.doe@example.com\"))\n",
        "print(pii_filter(\"Plan a trip to Paris\"))"
      ],
      "id": "d404cba5",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'blocked': True, 'reason': \"Potential PII detected: 'name'\", 'action': 'Redact or sanitize input'}\n",
            "{'blocked': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3222e2e1",
      "metadata": {
        "id": "3222e2e1"
      },
      "source": [
        "## 5Ô∏è‚É£ Tools (Dynamic Inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "28a3588c",
      "metadata": {
        "id": "28a3588c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "# üáÆüá≥ Domestic Trip Tool\n",
        "# This tool is specifically designed to handle travel plans within India.\n",
        "# It's an example of a specialized function that an AI agent might call.\n",
        "@tool\n",
        "def within_india_trip_tool(destination: str, days: int, budget: int) -> dict:\n",
        "    \"\"\"\n",
        "    Plan a domestic trip within India.\n",
        "\n",
        "    Inputs:\n",
        "    - destination: city or state name\n",
        "    - days: number of travel days\n",
        "    - budget: total budget in INR\n",
        "\n",
        "    Output:\n",
        "    - Structured domestic travel plan\n",
        "    \"\"\"\n",
        "    # This block defines the specific output structure for a domestic trip.\n",
        "    # It includes details like hotel type, common assumptions, and potential risks,\n",
        "    # providing a rich, structured response to the user's request.\n",
        "    return {\n",
        "        \"destination\": destination,\n",
        "        \"duration_days\": days,\n",
        "        \"budget_estimate\": budget,\n",
        "        \"hotel_type\": \"3-star\",\n",
        "        \"assumptions\": [\n",
        "            \"Domestic travel\",\n",
        "            \"Economy accommodation\"\n",
        "        ],\n",
        "        \"risks\": [\n",
        "            \"Weather dependency\",\n",
        "            \"Seasonal crowd\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "# üåç International Trip Tool\n",
        "# This tool handles travel plans to destinations outside India, requiring different considerations.\n",
        "@tool\n",
        "def outside_india_trip_tool(destination: str, days: int, budget: int) -> dict:\n",
        "    \"\"\"\n",
        "    Plan an international trip.\n",
        "\n",
        "    Inputs:\n",
        "    - destination: country or city name\n",
        "    - days: number of travel days\n",
        "    - budget: total budget in INR\n",
        "\n",
        "    Output:\n",
        "    - Structured international travel plan\n",
        "    \"\"\"\n",
        "    # This output structure is tailored for international travel, reflecting specific factors\n",
        "    # like visa requirements and currency fluctuations that are relevant globally.\n",
        "    return {\n",
        "        \"destination\": destination,\n",
        "        \"duration_days\": days,\n",
        "        \"budget_estimate\": budget,\n",
        "        \"hotel_type\": \"4-star\",\n",
        "        \"assumptions\": [\n",
        "            \"Visa approved\",\n",
        "            \"International flights available\"\n",
        "        ],\n",
        "        \"risks\": [\n",
        "            \"Visa delay\",\n",
        "            \"Currency fluctuation\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "# üßë‚Äçüíª College Hackathon Tool\n",
        "# A tool for organizing hackathons specifically tailored for a college environment.\n",
        "@tool\n",
        "def college_hackathon_tool(theme: str, team_size: int) -> dict:\n",
        "    \"\"\"\n",
        "    Organize a college-level hackathon.\n",
        "\n",
        "    Inputs:\n",
        "    - theme: hackathon theme\n",
        "    - team_size: members per team\n",
        "\n",
        "    Output:\n",
        "    - College hackathon configuration\n",
        "    \"\"\"\n",
        "    # The output specifies parameters relevant to a college hackathon, such as a typical duration.\n",
        "    return {\n",
        "        \"type\": \"College Hackathon\",\n",
        "        \"theme\": theme,\n",
        "        \"team_size\": team_size,\n",
        "        \"duration_hours\": 36\n",
        "    }\n",
        "\n",
        "\n",
        "# üè¢ Corporate Hackathon Tool\n",
        "# This tool is for organizing hackathons in a corporate setting, which may have different requirements.\n",
        "@tool\n",
        "def corporate_hackathon_tool(theme: str, team_size: int) -> dict:\n",
        "    \"\"\"\n",
        "    Organize a corporate-level hackathon.\n",
        "\n",
        "    Inputs:\n",
        "    - theme: hackathon theme\n",
        "    - team_size: members per team\n",
        "\n",
        "    Output:\n",
        "    - Corporate hackathon configuration\n",
        "    \"\"\"\n",
        "    # The output reflects corporate hackathon specifics, like a potentially longer duration.\n",
        "    return {\n",
        "        \"type\": \"Corporate Hackathon\",\n",
        "        \"theme\": theme,\n",
        "        \"team_size\": team_size,\n",
        "        \"duration_hours\": 48\n",
        "    }\n",
        "\n",
        "\n",
        "# üéâ Small Event Tool\n",
        "# A tool to plan smaller, private social events.\n",
        "@tool\n",
        "def small_event_tool(event_type: str, guests: int) -> dict:\n",
        "    \"\"\"\n",
        "    Plan a small private event.\n",
        "\n",
        "    Inputs:\n",
        "    - event_type: birthday, family meet, get-together\n",
        "    - guests: number of attendees\n",
        "\n",
        "    Output:\n",
        "    - Small event planning details\n",
        "    \"\"\"\n",
        "    # Details specific to small events, often including simpler activity suggestions.\n",
        "    return {\n",
        "        \"event_type\": event_type,\n",
        "        \"guests\": guests,\n",
        "        \"activities\": [\n",
        "            \"Music\",\n",
        "            \"Games\",\n",
        "            \"Food\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "# üé™ Large Event Tool\n",
        "# This tool is for planning large-scale public events, with more complex requirements.\n",
        "@tool\n",
        "def large_event_tool(event_type: str, guests: int) -> dict:\n",
        "    \"\"\"\n",
        "    Plan a large public event.\n",
        "\n",
        "    Inputs:\n",
        "    - event_type: concert, festival, celebration\n",
        "    - guests: number of attendees\n",
        "\n",
        "    Output:\n",
        "    - Large-scale event planning details\n",
        "    \"\"\"\n",
        "    # Output tailored for large events, which involve complex logistics like security and catering.\n",
        "    return {\n",
        "        \"event_type\": event_type,\n",
        "        \"guests\": guests,\n",
        "        \"activities\": [\n",
        "            \"Stage Show\",\n",
        "            \"Catering\",\n",
        "            \"Security\"\n",
        "        ]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c2da0d",
      "metadata": {
        "id": "c8c2da0d"
      },
      "source": [
        "## 6Ô∏è‚É£ Brain Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bab5c07f",
      "metadata": {
        "id": "bab5c07f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def brain_decide_agent(goal: str):\n",
        "    \"\"\"\n",
        "    Acts as the primary router, deciding which specialized agent should handle the user's request.\n",
        "\n",
        "    This function is critical for the agentic system's modularity, ensuring that\n",
        "    each request is directed to the most appropriate backend tool or agent.\n",
        "    It uses the LLM to categorize the user's intent.\n",
        "    \"\"\"\n",
        "    # Construct a clear and concise prompt for the LLM.\n",
        "    # The prompt instructs the LLM to act as a decision-making brain and to output\n",
        "    # its decision in a strict JSON format, selecting one of the predefined agents.\n",
        "    prompt = f\"\"\"\n",
        "You are a decision-making brain.\n",
        "\n",
        "Respond with ONLY valid JSON.\n",
        "No explanation text.\n",
        "\n",
        "Choose one agent:\n",
        "- vacation\n",
        "- hackathon\n",
        "- social_event\n",
        "- unknown\n",
        "\n",
        "JSON format:\n",
        "{{\n",
        "  \"agent\": \"vacation | hackathon | social_event | unknown\",\n",
        "  \"confidence\": 0.0,\n",
        "  \"reason\": \"short reason\"\n",
        "}}\n",
        "\n",
        "User goal: \"{goal}\"\n",
        "\"\"\"\n",
        "\n",
        "    # Invoke the LLM (Large Language Model) with the crafted prompt.\n",
        "    # The LLM processes the user's goal and returns its decision as raw text.\n",
        "    raw = llm.invoke(prompt).content\n",
        "\n",
        "    # Safely parse the raw LLM output into a structured JSON object.\n",
        "    # The `safe_json_parse` function is used here to handle potential formatting\n",
        "    # issues in the LLM's response, providing a robust parsing mechanism.\n",
        "    # A `fallback` dictionary is provided to ensure a default decision if parsing fails.\n",
        "    return safe_json_parse(\n",
        "        raw,\n",
        "        fallback={\n",
        "            \"agent\": \"unknown\",\n",
        "            \"confidence\": 0.0,\n",
        "            \"reason\": \"Invalid or empty model response\"\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e229900",
      "metadata": {
        "id": "2e229900"
      },
      "source": [
        "## 7Ô∏è‚É£ Vacation Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0cd1a049",
      "metadata": {
        "id": "0cd1a049"
      },
      "outputs": [],
      "source": [
        "def vacation_agent(goal: str):\n",
        "    \"\"\"\n",
        "    Specialized agent for planning vacation trips.\n",
        "\n",
        "    It extracts key details like destination, duration, and budget from the user's request\n",
        "    and then routes the request to either a 'within_india' or 'outside_india' trip planning tool.\n",
        "    \"\"\"\n",
        "    print(\"\\nüß† Vacation agent reasoning...\")\n",
        "\n",
        "    # Formulate a specific prompt to instruct the LLM to act as an information extraction system.\n",
        "    # The prompt guides the LLM to identify critical parameters for vacation planning\n",
        "    # (destination, days, budget) and to decide between domestic or international tools.\n",
        "    prompt = f\"\"\"\n",
        "You are an information extraction system.\n",
        "\n",
        "Extract the following from the user request:\n",
        "- destination (string)\n",
        "- number of days (integer)\n",
        "- budget in INR (integer)\n",
        "\n",
        "Rules:\n",
        "- Do NOT guess\n",
        "- If a value is missing, infer reasonably\n",
        "- Explain clearly WHY the chosen tool is appropriate\n",
        "- Assign a realistic confidence score (0.5‚Äì0.95)\n",
        "- Return ONLY valid JSON\n",
        "- NO explanation text\n",
        "\n",
        "JSON format:\n",
        "{{\n",
        "  \"tool\": \"within_india | outside_india\",\n",
        "  \"destination\": \"\",\n",
        "  \"days\": 0,\n",
        "  \"budget\": 0,\n",
        "  \"tool_confidence\": 0.0,\n",
        "  \"reason\": \"Why this tool is appropriate\"\n",
        "}}\n",
        "\n",
        "User request:\n",
        "\"{goal}\"\n",
        "\"\"\"\n",
        "\n",
        "    # Send the extraction prompt to the LLM and capture its raw text output.\n",
        "    raw = llm.invoke(prompt).content\n",
        "    print(\"üîç Raw LLM extraction:\", raw)\n",
        "\n",
        "    # Parse the LLM's raw output into a structured decision dictionary.\n",
        "    # The `safe_json_parse` function ensures robustness against malformed LLM responses.\n",
        "    # A default fallback is provided if extraction or parsing fails, ensuring continuity.\n",
        "    decision = safe_json_parse(\n",
        "        raw,\n",
        "        {\n",
        "            \"tool\": \"within_india\",\n",
        "            \"destination\": \"Unknown\",\n",
        "            \"days\": 3,\n",
        "            \"budget\": 30000,\n",
        "            \"reason\": \"Fallback values used\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # üîê HARD VALIDATION (IMPORTANT): Ensure 'days' is an integer.\n",
        "    # This step converts the extracted 'days' value to an integer, as the tool expects it.\n",
        "    # It's a crucial type enforcement for robust tool invocation.\n",
        "    if not isinstance(decision.get(\"days\"), int):\n",
        "        decision[\"days\"] = int(decision[\"days\"])\n",
        "\n",
        "    # üîê HARD VALIDATION (IMPORTANT): Ensure 'budget' is an integer.\n",
        "    # Similarly, the 'budget' is cast to an integer to match the tool's expected input type.\n",
        "    if not isinstance(decision.get(\"budget\"), int):\n",
        "        decision[\"budget\"] = int(decision[\"budget\"])\n",
        "\n",
        "    print(\"‚úÖ Parsed decision:\", decision)\n",
        "\n",
        "    # Based on the 'tool' determined by the LLM (either 'within_india' or 'outside_india'),\n",
        "    # the appropriate trip planning tool is invoked with the extracted parameters.\n",
        "    if decision[\"tool\"] == \"within_india\":\n",
        "        result = within_india_trip_tool.invoke({\n",
        "            \"destination\": decision[\"destination\"],\n",
        "            \"days\": decision[\"days\"],\n",
        "            \"budget\": decision[\"budget\"]\n",
        "        })\n",
        "    else:\n",
        "        result = outside_india_trip_tool.invoke({\n",
        "            \"destination\": decision[\"destination\"],\n",
        "            \"days\": decision[\"days\"],\n",
        "            \"budget\": decision[\"budget\"]\n",
        "        })\n",
        "\n",
        "    # Finally, return a structured result from the vacation agent, summarizing\n",
        "    # which agent and tool were used, the reasoning, and the plan generated by the tool.\n",
        "    return {\n",
        "        \"agent\": \"Vacation Organizer\",\n",
        "        \"tool_used\": decision[\"tool\"],\n",
        "        \"reason\": decision[\"reason\"],\n",
        "        \"result\": result\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f264e96e",
      "metadata": {
        "id": "f264e96e"
      },
      "source": [
        "## 8Ô∏è‚É£ Hackathon Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "653123ba",
      "metadata": {
        "id": "653123ba"
      },
      "outputs": [],
      "source": [
        "def hackathon_agent(goal: str):\n",
        "    \"\"\"\n",
        "    Specialized agent for organizing hackathons.\n",
        "\n",
        "    It extracts the hackathon type (college/corporate), theme, and team size\n",
        "    from the user's request and invokes the corresponding hackathon planning tool.\n",
        "    \"\"\"\n",
        "    print(\"\\nüß† Hackathon agent reasoning...\")\n",
        "\n",
        "    # Define the prompt for the LLM, instructing it to extract specific details\n",
        "    # related to hackathon organization, such as type, theme, and team size.\n",
        "    # The LLM is also guided to output its findings in a consistent JSON format.\n",
        "    prompt = f\"\"\"\n",
        "You are an information extraction system.\n",
        "\n",
        "Extract the following from the user request:\n",
        "- hackathon type: college or corporate\n",
        "- theme (string)\n",
        "- team size (integer)\n",
        "\n",
        "Rules:\n",
        "- Do NOT guess wildly\n",
        "- Infer reasonably if missing\n",
        "- Return ONLY valid JSON\n",
        "- NO explanation text\n",
        "\n",
        "JSON format:\n",
        "{{\n",
        "  \"tool\": \"college | corporate\",\n",
        "  \"theme\": \"\",\n",
        "  \"team_size\": 0,\n",
        "  \"tool_confidence\": 0.0,\n",
        "  \"reason\": \"Why this tool is appropriate\"\n",
        "}}\n",
        "\n",
        "User request:\n",
        "\"{goal}\"\n",
        "\"\"\"\n",
        "\n",
        "    # Invoke the LLM with the prompt to perform the information extraction.\n",
        "    # The raw text response from the LLM is captured for subsequent parsing.\n",
        "    raw = llm.invoke(prompt).content\n",
        "    print(\"üîç Raw LLM extraction:\", raw)\n",
        "\n",
        "    # Safely parse the raw LLM output into a structured dictionary.\n",
        "    # `safe_json_parse` handles potential parsing errors, and a fallback provides defaults.\n",
        "    decision = safe_json_parse(\n",
        "        raw,\n",
        "        {\n",
        "            \"tool\": \"college\",\n",
        "            \"theme\": \"General Technology\",\n",
        "            \"team_size\": 4,\n",
        "            \"reason\": \"Fallback values used\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # üîê HARD VALIDATION: Ensure 'team_size' is an integer.\n",
        "    # This is important to ensure the tool receives numerical input as expected.\n",
        "    if not isinstance(decision.get(\"team_size\"), int):\n",
        "        decision[\"team_size\"] = int(decision[\"team_size\"])\n",
        "\n",
        "    print(\"‚úÖ Parsed decision:\", decision)\n",
        "\n",
        "    # Route the request to either the 'college_hackathon_tool' or 'corporate_hackathon_tool'\n",
        "    # based on the LLM's classification of the hackathon type.\n",
        "    if decision[\"tool\"] == \"college\":\n",
        "        result = college_hackathon_tool.invoke({\n",
        "            \"theme\": decision[\"theme\"],\n",
        "            \"team_size\": decision[\"team_size\"]\n",
        "        })\n",
        "    else:\n",
        "        result = corporate_hackathon_tool.invoke({\n",
        "            \"theme\": decision[\"theme\"],\n",
        "            \"team_size\": decision[\"team_size\"]\n",
        "        })\n",
        "\n",
        "    # Return a comprehensive result from the hackathon agent, detailing the chosen tool\n",
        "    # and the structured output from that tool.\n",
        "    return {\n",
        "        \"agent\": \"Hackathon Organizer\",\n",
        "        \"tool_used\": decision[\"tool\"],\n",
        "        \"reason\": decision[\"reason\"],\n",
        "        \"result\": result\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa18405a",
      "metadata": {
        "id": "aa18405a"
      },
      "source": [
        "## 9Ô∏è‚É£ Social Event Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b105e888",
      "metadata": {
        "id": "b105e888"
      },
      "outputs": [],
      "source": [
        "def social_event_agent(goal: str):\n",
        "    \"\"\"\n",
        "    Specialized agent for planning social events.\n",
        "\n",
        "    It extracts the event type and number of guests from the user's request\n",
        "    and categorizes the event as 'small' or 'large' to invoke the appropriate tool.\n",
        "    \"\"\"\n",
        "    print(\"\\nüß† Social Event agent reasoning...\")\n",
        "\n",
        "    # Create a prompt for the LLM to extract key information for social event planning.\n",
        "    # This includes the event type, number of guests, and the inferred scale of the event.\n",
        "    prompt = f\"\"\"\n",
        "You are an information extraction system.\n",
        "\n",
        "Extract the following from the user request:\n",
        "- event type (string)\n",
        "- number of guests (integer)\n",
        "- event scale: small or large\n",
        "\n",
        "Rules:\n",
        "- Do NOT guess wildly\n",
        "- Infer reasonably if missing\n",
        "- Return ONLY valid JSON\n",
        "- NO explanation text\n",
        "\n",
        "JSON format:\n",
        "{{\n",
        "  \"tool\": \"small | large\",\n",
        "  \"event_type\": \"\",\n",
        "  \"guests\": 0,\n",
        " \"tool_confidence\": 0.0,\n",
        "  \"reason\": \"Why this tool is appropriate\"\n",
        "}}\n",
        "\n",
        "User request:\n",
        "\"{goal}\"\n",
        "\"\"\"\n",
        "\n",
        "    # Execute the LLM with the extraction prompt and retrieve the raw response.\n",
        "    raw = llm.invoke(prompt).content\n",
        "    print(\"üîç Raw LLM extraction:\", raw)\n",
        "\n",
        "    # Parse the LLM's raw output into a structured decision, using `safe_json_parse`\n",
        "    # to handle potential inconsistencies and provide default values if necessary.\n",
        "    decision = safe_json_parse(\n",
        "        raw,\n",
        "        {\n",
        "            \"tool\": \"small\",\n",
        "            \"event_type\": \"General Event\",\n",
        "            \"guests\": 30,\n",
        "            \"reason\": \"Fallback values used\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # üîê HARD VALIDATION: Ensure 'guests' is an integer.\n",
        "    # This step converts the guest count to an integer to ensure correct input for the tools.\n",
        "    if not isinstance(decision.get(\"guests\"), int):\n",
        "        decision[\"guests\"] = int(decision[\"guests\"])\n",
        "\n",
        "    print(\"‚úÖ Parsed decision:\", decision)\n",
        "\n",
        "    # Based on whether the LLM classified the event as 'small' or 'large',\n",
        "    # the appropriate social event planning tool is called.\n",
        "    if decision[\"tool\"] == \"small\":\n",
        "        result = small_event_tool.invoke({\n",
        "            \"event_type\": decision[\"event_type\"],\n",
        "            \"guests\": decision[\"guests\"]\n",
        "        })\n",
        "    else:\n",
        "        result = large_event_tool.invoke({\n",
        "            \"event_type\": decision[\"event_type\"],\n",
        "            \"guests\": decision[\"guests\"]\n",
        "        })\n",
        "\n",
        "    # Return a comprehensive summary of the social event planning, including\n",
        "    # the agent, tool used, reasoning, and the structured event plan.\n",
        "    return {\n",
        "        \"agent\": \"Social Event Organizer\",\n",
        "        \"tool_used\": decision[\"tool\"],\n",
        "        \"reason\": decision[\"reason\"],\n",
        "        \"result\": result\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f15afc1",
      "metadata": {
        "id": "6f15afc1"
      },
      "source": [
        " üîü Master Agent Controller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b2425a81",
      "metadata": {
        "id": "b2425a81"
      },
      "outputs": [],
      "source": [
        "def agentic_ai_system(goal: str):\n",
        "    \"\"\"\n",
        "    The master controller of the agentic AI system.\n",
        "\n",
        "    This function orchestrates the entire process: from initial guardrail checks\n",
        "    to routing the request to the correct specialized agent (vacation, hackathon, or social event).\n",
        "    It ensures safety and proper delegation of tasks.\n",
        "    \"\"\"\n",
        "    # Step 1: Initial Guardrail Check.\n",
        "    # Before any processing, the user's input 'goal' is checked against defined safety policies.\n",
        "    # This is a critical first line of defense against inappropriate or unsafe requests.\n",
        "    guard = guardrail_check(goal)\n",
        "    if guard[\"blocked\"]:\n",
        "        # If the guardrail detects a violation, immediately return the blocking response.\n",
        "        # No further processing occurs, ensuring the system adheres to safety guidelines.\n",
        "        return guard\n",
        "\n",
        "    # Step 2: Brain Agent Decision.\n",
        "    # If the goal passes the guardrail, the `brain_decide_agent` is invoked.\n",
        "    # This agent acts as a router, determining which specialized agent (e.g., vacation, hackathon)\n",
        "    # is best suited to handle the user's specific request.\n",
        "    brain = brain_decide_agent(goal)\n",
        "\n",
        "    # Step 3: Route to Specialized Agent.\n",
        "    # Based on the decision from the `brain` agent, the request is dispatched\n",
        "    # to the appropriate specialized agent for detailed processing.\n",
        "    if brain[\"agent\"] == \"vacation\":\n",
        "        return vacation_agent(goal)\n",
        "    elif brain[\"agent\"] == \"hackathon\":\n",
        "        return hackathon_agent(goal)\n",
        "    elif brain[\"agent\"] == \"social_event\":\n",
        "        return social_event_agent(goal)\n",
        "    else:\n",
        "        # If the brain agent cannot confidently determine a suitable specialized agent,\n",
        "        # an \"uncertain\" status is returned. This indicates that the system either\n",
        "        # does not have a tool for this request or could not understand the intent.\n",
        "        return {\"status\": \"uncertain\", \"message\": \"Request cannot be handled reliably\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ecd228",
      "metadata": {
        "id": "f6ecd228"
      },
      "source": [
        "## ‚ñ∂Ô∏è Demo Runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2aa68600",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aa68600",
        "outputId": "1c0661c3-4792-4e75-d5dd-4fd92f88cf44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Vacation agent reasoning...\n",
            "üîç Raw LLM extraction: {\n",
            "  \"tool\": \"within_india\",\n",
            "  \"destination\": \"Forest\",\n",
            "  \"days\": 10,\n",
            "  \"budget\": 40000,\n",
            "  \"tool_confidence\": 0.8,\n",
            "  \"reason\": \"The user mentioned 'Forest' which is a common name for a forest in India, suggesting a domestic trip.\"\n",
            "}\n",
            "‚úÖ Parsed decision: {'tool': 'within_india', 'destination': 'Forest', 'days': 10, 'budget': 40000, 'tool_confidence': 0.8, 'reason': \"The user mentioned 'Forest' which is a common name for a forest in India, suggesting a domestic trip.\"}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agent': 'Vacation Organizer',\n",
              " 'tool_used': 'within_india',\n",
              " 'reason': \"The user mentioned 'Forest' which is a common name for a forest in India, suggesting a domestic trip.\",\n",
              " 'result': {'destination': 'Forest',\n",
              "  'duration_days': 10,\n",
              "  'budget_estimate': 40000,\n",
              "  'hotel_type': '3-star',\n",
              "  'assumptions': ['Domestic travel', 'Economy accommodation'],\n",
              "  'risks': ['Weather dependency', 'Seasonal crowd']}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "agentic_ai_system(\"Plan a 10 day trip to Forest anywhere with 40k budget suggest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6a94922c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a94922c",
        "outputId": "d9981ea3-e7b7-434f-88f6-3eb8206b7337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Hackathon agent reasoning...\n",
            "üîç Raw LLM extraction: {\n",
            "  \"tool\": \"college\",\n",
            "  \"theme\": \"all india hackathon finals in delhi\",\n",
            "  \"team_size\": 0,\n",
            "  \"tool_confidence\": 1.0,\n",
            "  \"reason\": \"The term 'all india' suggests a national scope, which is often associated with college-level hackathons.\"\n",
            "}\n",
            "‚úÖ Parsed decision: {'tool': 'college', 'theme': 'all india hackathon finals in delhi', 'team_size': 0, 'tool_confidence': 1.0, 'reason': \"The term 'all india' suggests a national scope, which is often associated with college-level hackathons.\"}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agent': 'Hackathon Organizer',\n",
              " 'tool_used': 'college',\n",
              " 'reason': \"The term 'all india' suggests a national scope, which is often associated with college-level hackathons.\",\n",
              " 'result': {'type': 'College Hackathon',\n",
              "  'theme': 'all india hackathon finals in delhi',\n",
              "  'team_size': 0,\n",
              "  'duration_hours': 36}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "agentic_ai_system(\"Organize a all india hackathon finals in delhi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ae75b466",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae75b466",
        "outputId": "bab2dfd2-6f9c-4ea9-e6be-041837984d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Social Event agent reasoning...\n",
            "üîç Raw LLM extraction: {\n",
            "  \"tool\": \"large\",\n",
            "  \"event_type\": \"politics party\",\n",
            "  \"guests\": 1000,\n",
            "  \"tool_confidence\": 1.0,\n",
            "  \"reason\": \"The event type is politics party and the number of guests is 1000, which is a large scale event.\"\n",
            "}\n",
            "‚úÖ Parsed decision: {'tool': 'large', 'event_type': 'politics party', 'guests': 1000, 'tool_confidence': 1.0, 'reason': 'The event type is politics party and the number of guests is 1000, which is a large scale event.'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agent': 'Social Event Organizer',\n",
              " 'tool_used': 'large',\n",
              " 'reason': 'The event type is politics party and the number of guests is 1000, which is a large scale event.',\n",
              " 'result': {'event_type': 'politics party',\n",
              "  'guests': 1000,\n",
              "  'activities': ['Stage Show', 'Catering', 'Security']}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "agentic_ai_system(\"Plan a politics party for 1000 guests\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b484c13d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b484c13d",
        "outputId": "ac4e08d2-dc45-4fc1-ed79-b54c9d5f152e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'blocked': True,\n",
              " 'reason': 'Financial market prediction is unreliable and unsafe',\n",
              " 'safe_alternatives': ['Explain how stock prices generally work',\n",
              "  'Discuss investment risk factors',\n",
              "  'Show historical trends']}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "agentic_ai_system(\"Stock market price next min predict\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}