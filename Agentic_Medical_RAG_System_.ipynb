{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balavignesh-25/Agentic-AI-System/blob/main/Agentic_Medical_RAG_System_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "DCYen2Iy0bqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6132bafa"
      },
      "source": [
        "# Agentic Medical RAG System for Hypertension Explanation\n",
        "\n",
        "This project implements a lightweight, **agentic Retrieval-Augmented Generation (RAG) system** focused on explaining medical concepts, specifically hypertension. A key feature of this system is that it operates **without external API keys (like OpenAI) and avoids heavy NLP libraries like NLTK**, making it entirely free and self-contained. It leverages a multi-agent architecture to retrieve, generate, evaluate, and summarize information.\n",
        "\n",
        "## Project Title\n",
        "**Agentic Medical RAG System for Hypertension Explanation (No NLTK/API Keys)**\n",
        "\n",
        "## Features\n",
        "\n",
        "*   **Internal Knowledge Base:** A static, predefined set of medical facts about hypertension.\n",
        "*   **External Knowledge Retrieval:** Integrates with Wikipedia for dynamic information retrieval, acting as an 'external' source.\n",
        "*   **Basic NLP Utilities:** Custom-built functions for tokenization and sentence splitting, avoiding heavy external dependencies.\n",
        "*   **Multi-Agent Architecture:**\n",
        "    *   **Planner Agent:** Orchestrates the flow of information by defining a sequence of steps.\n",
        "    *   **Retriever Agent:** Fetches relevant information from both internal KB and Wikipedia.\n",
        "    *   **Generator Agent:** Synthesizes retrieved information into a coherent answer.\n",
        "    *   **Critic Agent:** Evaluates the generated answer for quality, relevance, and completeness, triggering refinement if necessary.\n",
        "    *   **Summarizer Agent:** Condenses the final answer using basic NLP techniques.\n",
        "*   **Pure Python/No-API:** No reliance on expensive or external LLM APIs for core generation or complex NLP tasks.\n",
        "*   **Execution Trace:** Provides a detailed log of agent activities and decisions during the RAG process.\n",
        "\n",
        "## Architecture Overview\n",
        "\n",
        "The system follows a sequential agentic workflow:\n",
        "\n",
        "1.  **Planning:** A `planner` agent defines the execution steps (retrieve internal, retrieve external, generate, evaluate, summarize).\n",
        "2.  **Retrieval:** The system first queries its `INTERNAL_MEDICAL_KB` and then fetches supplementary information from Wikipedia using `retrieve_wikipedia`.\n",
        "3.  **Generation:** A `generate_answer` function combines the retrieved internal and external documents to form a draft response.\n",
        "4.  **Critique & Refinement:** A `critic_agent` assesses the quality and completeness of the draft. If deemed insufficient, it might trigger a refinement step (e.g., adding more details from the KB).\n",
        "5.  **Summarization:** Finally, a `nlp_summarize` function condenses the (potentially refined) answer into a concise summary.\n",
        "\n",
        "This agentic loop allows for self-correction and ensures a more robust and informative output.\n",
        "\n",
        "## Setup and How to Run\n",
        "\n",
        "To set up and run this project, follow these steps:\n",
        "\n",
        "1.  **Clone the repository (if applicable) or copy the code into a Colab notebook.**\n",
        "\n",
        "2.  **Install the necessary libraries:**\n",
        "    The project primarily uses `wikipedia` and `re`. The `wikipedia` library is crucial for external knowledge retrieval.\n",
        "\n",
        "    ```bash\n",
        "    !pip install wikipedia\n",
        "    ```\n",
        "\n",
        "3.  **Execute the code:**\n",
        "    The core logic is contained within the `agentic_medical_rag` function. You can run the demo by defining a query and calling the function:\n",
        "\n",
        "    ```python\n",
        "    query = \"Explain the causes and risk factors of hypertension in simple terms.\"\n",
        "    final_answer = agentic_medical_rag(query)\n",
        "\n",
        "    print(\"\\n‚úÖ FINAL ANSWER:\\n\")\n",
        "    print(final_answer)\n",
        "    ```\n",
        "\n",
        "    The script will print the step-by-step execution trace of the agents, followed by the final summarized answer.\n",
        "\n",
        "## Example Usage\n",
        "\n",
        "**Query:** `\"Explain the causes and risk factors of hypertension in simple terms.\"`\n",
        "\n",
        "**Expected Output Structure (simplified):**\n",
        "\n",
        "```\n",
        "ü§ñ AGENT ACTIVATED\n",
        "üéØ GOAL: Explain the causes and risk factors of hypertension in simple terms.\n",
        "üß† PLAN: ['retrieve_internal', 'retrieve_external', 'generate', 'evaluate', 'summarize']\n",
        "\n",
        "‚û° EXECUTING: retrieve_internal\n",
        "üìö Internal KB used\n",
        "\n",
        "‚û° EXECUTING: retrieve_external\n",
        "üåç Wikipedia consulted\n",
        "\n",
        "‚û° EXECUTING: generate\n",
        "‚úç Draft answer generated\n",
        "\n",
        "‚û° EXECUTING: evaluate\n",
        "üîç Critic: Answer is sufficient\n",
        "\n",
        "‚û° EXECUTING: summarize\n",
        "üìù Summary created\n",
        "\n",
        "‚úÖ FINAL ANSWER:\n",
        "[Summarized explanation about hypertension causes and risk factors]\n",
        "```\n",
        "\n",
        "This project serves as an excellent demonstration of building a RAG system with basic NLP and agentic principles without relying on complex, external, or paid services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npazMvDS0wix"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# FULL AGENTIC MEDICAL RAG SYSTEM\n",
        "# NO NLTK | NO API KEYS | FREE\n",
        "# ==============================\n",
        "\n",
        "# !pip install wikipedia\n",
        "\n",
        "import wikipedia\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# ------------------------------\n",
        "# INTERNAL MEDICAL KNOWLEDGE BASE\n",
        "# This section defines a simple, static knowledge base for medical information.\n",
        "# ------------------------------\n",
        "INTERNAL_MEDICAL_KB = [\n",
        "    \"Hypertension means long-term high blood pressure in the arteries.\",\n",
        "    \"It usually develops slowly and often has no early symptoms.\",\n",
        "    \"Eating too much salt can raise blood pressure.\",\n",
        "    \"Being overweight makes the heart work harder.\",\n",
        "    \"Smoking damages blood vessels and raises blood pressure.\",\n",
        "    \"Lack of exercise weakens the heart and blood vessels.\",\n",
        "    \"Drinking too much alcohol increases blood pressure.\",\n",
        "    \"Family history increases the risk of hypertension.\",\n",
        "    \"Kidney disease and hormone problems can cause secondary hypertension.\",\n",
        "    \"High blood pressure increases the risk of heart attack and stroke.\"\n",
        "]\n",
        "\n",
        "# ------------------------------\n",
        "# BASIC NLP UTILITIES (NO NLTK)\n",
        "# These functions provide basic Natural Language Processing capabilities\n",
        "# without relying on external NLP libraries like NLTK.\n",
        "# ------------------------------\n",
        "def split_sentences(text):\n",
        "    # Splits a given text into individual sentences.\n",
        "    return re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "\n",
        "def tokenize(text):\n",
        "    # Converts text to lowercase and extracts individual words (tokens).\n",
        "    return re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
        "\n",
        "# ------------------------------\n",
        "# INTERNAL KB RETRIEVER\n",
        "# This function searches the internal knowledge base for relevant information.\n",
        "# ------------------------------\n",
        "def retrieve_internal_kb(query, top_k=3):\n",
        "    # Tokenizes the query to find matching words in the internal documents.\n",
        "    query_words = set(tokenize(query))\n",
        "    scored = []\n",
        "\n",
        "    # Scores each document based on the number of shared words with the query.\n",
        "    for doc in INTERNAL_MEDICAL_KB:\n",
        "        score = len(query_words & set(tokenize(doc)))\n",
        "        scored.append((score, doc))\n",
        "\n",
        "    # Sorts documents by score and returns the top_k most relevant ones.\n",
        "    scored.sort(reverse=True)\n",
        "    return [doc for score, doc in scored[:top_k]]\n",
        "\n",
        "# ------------------------------\n",
        "# EXTERNAL KNOWLEDGE TOOL (WIKI)\n",
        "# This function retrieves information from Wikipedia for external context.\n",
        "# ------------------------------\n",
        "def retrieve_wikipedia(query, sentences=4):\n",
        "    try:\n",
        "        # Searches Wikipedia for the query and retrieves a summary.\n",
        "        title = wikipedia.search(query)[0]\n",
        "        return wikipedia.summary(title, sentences=sentences)\n",
        "    except Exception:\n",
        "        # Returns a fallback message if Wikipedia retrieval fails.\n",
        "        return \"External medical knowledge could not be retrieved.\"\n",
        "\n",
        "# ------------------------------\n",
        "# ANSWER GENERATOR\n",
        "# This function combines retrieved information to form a coherent answer.\n",
        "# ------------------------------\n",
        "def generate_answer(query, internal_docs, wiki_text):\n",
        "    answer = \"Here is a simple explanation:\\n\\n\"\n",
        "\n",
        "    # Appends information from the internal knowledge base.\n",
        "    for doc in internal_docs:\n",
        "        answer += \"- \" + doc + \"\\n\"\n",
        "\n",
        "    # Appends additional information from Wikipedia.\n",
        "    answer += \"\\nAdditional information:\\n\"\n",
        "    answer += wiki_text\n",
        "    return answer\n",
        "\n",
        "# ------------------------------\n",
        "# PURE NLP SUMMARIZER (NO LLM)\n",
        "# This function summarizes text using basic NLP techniques without an LLM.\n",
        "# ------------------------------\n",
        "def nlp_summarize(text, num_sentences=3):\n",
        "    # Splits text into sentences and tokenizes words.\n",
        "    sentences = split_sentences(text)\n",
        "    words = tokenize(text)\n",
        "    # Calculates word frequencies.\n",
        "    freq = Counter(words)\n",
        "\n",
        "    sentence_scores = {}\n",
        "    # Scores each sentence based on the frequency of its words.\n",
        "    for s in sentences:\n",
        "        sentence_scores[s] = sum(freq[w] for w in tokenize(s))\n",
        "\n",
        "    # Ranks sentences by score and returns the top_k as a summary.\n",
        "    ranked = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
        "    return \" \".join(ranked[:num_sentences])\n",
        "\n",
        "# ------------------------------\n",
        "# CRITIC AGENT\n",
        "# This agent evaluates the generated answer for quality and completeness.\n",
        "# ------------------------------\n",
        "def evaluate_answer(answer):\n",
        "    # Checks if the answer is too short or misses key concepts.\n",
        "    if len(answer.split()) < 60:\n",
        "        return False, \"Answer too shallow\"\n",
        "    if \"blood pressure\" not in answer.lower():\n",
        "        return False, \"Missing core concept\"\n",
        "    # Returns true if the answer is considered sufficient.\n",
        "    return True, \"Answer is sufficient\"\n",
        "\n",
        "# ------------------------------\n",
        "# PLANNING AGENT\n",
        "# This agent defines the sequence of steps for the RAG process.\n",
        "# ------------------------------\n",
        "def planner(goal):\n",
        "    # Returns a predefined plan for processing the medical query.\n",
        "    return [\n",
        "        \"retrieve_internal\",\n",
        "        \"retrieve_external\",\n",
        "        \"generate\",\n",
        "        \"evaluate\",\n",
        "        \"summarize\"\n",
        "    ]\n",
        "\n",
        "# ------------------------------\n",
        "# AGENTIC EXECUTION LOOP\n",
        "# This is the main orchestrator that executes the plan using different agents.\n",
        "# ------------------------------\n",
        "def agentic_medical_rag(query):\n",
        "    print(\"\\nü§ñ AGENT ACTIVATED\")\n",
        "    print(\"üéØ GOAL:\", query)\n",
        "\n",
        "    # Gets the plan from the planning agent.\n",
        "    plan = planner(query)\n",
        "    print(\"üß† PLAN:\", plan)\n",
        "\n",
        "    memory = {} # Stores intermediate results from each step.\n",
        "\n",
        "    for step in plan:\n",
        "        print(f\"\\n‚û° EXECUTING: {step}\")\n",
        "\n",
        "        if step == \"retrieve_internal\":\n",
        "            # Retrieves relevant documents from the internal knowledge base.\n",
        "            memory[\"internal\"] = retrieve_internal_kb(query)\n",
        "            print(\"üìö Internal KB used\")\n",
        "\n",
        "        elif step == \"retrieve_external\":\n",
        "            # Retrieves information from Wikipedia.\n",
        "            memory[\"wiki\"] = retrieve_wikipedia(query)\n",
        "            print(\"üåç Wikipedia consulted\")\n",
        "\n",
        "        elif step == \"generate\":\n",
        "            # Generates a draft answer using internal and external information.\n",
        "            memory[\"answer\"] = generate_answer(\n",
        "                query,\n",
        "                memory[\"internal\"],\n",
        "                memory[\"wiki\"]\n",
        "            )\n",
        "            print(\"‚úç Draft answer generated\")\n",
        "\n",
        "        elif step == \"evaluate\":\n",
        "            # Evaluates the draft answer using the critic agent.\n",
        "            ok, reason = evaluate_answer(memory[\"answer\"])\n",
        "            print(\"üîç Critic:\", reason)\n",
        "\n",
        "            if not ok:\n",
        "                # If the answer is insufficient, refines it by adding more info.\n",
        "                print(\"üîÅ Refining answer...\")\n",
        "                memory[\"internal\"].append(\n",
        "                    \"Hypertension damages blood vessels over time if untreated.\"\n",
        "                )\n",
        "                memory[\"answer\"] = generate_answer(\n",
        "                    query,\n",
        "                    memory[\"internal\"],\n",
        "                    memory[\"wiki\"]\n",
        "                )\n",
        "\n",
        "        elif step == \"summarize\":\n",
        "            # Summarizes the final answer using NLP summarizer.\n",
        "            memory[\"final\"] = nlp_summarize(memory[\"answer\"])\n",
        "            print(\"üìù Summary created\")\n",
        "\n",
        "    # Returns the final summarized answer.\n",
        "    return memory[\"final\"]\n",
        "\n",
        "# ------------------------------\n",
        "# RUN DEMO\n",
        "# This section demonstrates how to use the agentic medical RAG system.\n",
        "# ------------------------------\n",
        "query = \"Explain the causes and risk factors of hypertension in simple terms.\"\n",
        "final_answer = agentic_medical_rag(query)\n",
        "\n",
        "print(\"\\n‚úÖ FINAL ANSWER:\\n\")\n",
        "print(final_answer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers faiss-cpu transformers wikipedia beautifulsoup4 requests accelerate\n"
      ],
      "metadata": {
        "id": "xTLkLJOR0jMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "\n",
        "# !pip install -q sentence-transformers faiss-cpu transformers wikipedia beautifulsoup4 requests accelerate\n",
        "\n",
        "# =========================\n",
        "# IMPORTS\n",
        "# =========================\n",
        "import wikipedia\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import numpy as np\n",
        "import faiss\n",
        "import torch\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# =========================\n",
        "# EXECUTION TRACE TOOL\n",
        "# =========================\n",
        "TRACE_LOG = []\n",
        "\n",
        "def trace(step, message):\n",
        "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "    entry = f\"[{timestamp}] {step}: {message}\"\n",
        "    TRACE_LOG.append(entry)\n",
        "    print(entry)\n",
        "\n",
        "# =========================\n",
        "# INTERNAL KNOWLEDGE SCRAPER\n",
        "# =========================\n",
        "def scrape_text(url):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=10)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        text = \" \".join(p.get_text() for p in soup.find_all(\"p\"))\n",
        "        return text.strip()\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Hypertension\",\n",
        "    \"https://en.wikipedia.org/wiki/Blood_pressure\",\n",
        "    \"https://en.wikipedia.org/wiki/Cardiovascular_disease\"\n",
        "]\n",
        "\n",
        "trace(\"SCRAPER\", \"Collecting internal knowledge\")\n",
        "documents = []\n",
        "\n",
        "for u in urls:\n",
        "    text = scrape_text(u)\n",
        "    trace(\"SCRAPER_RETURN\", f\"Scraped {len(text)} characters from {u}\")\n",
        "    for i in range(0, len(text), 800):\n",
        "        chunk = text[i:i+800]\n",
        "        if len(chunk.strip()) > 200:\n",
        "            documents.append(chunk)\n",
        "\n",
        "# =========================\n",
        "# FALLBACK KNOWLEDGE\n",
        "# =========================\n",
        "if not documents:\n",
        "    trace(\"VALIDATOR\", \"No documents scraped ‚Äî activating fallback knowledge\")\n",
        "    documents = [\n",
        "        \"Hypertension is a condition where blood pressure stays high for a long time.\",\n",
        "        \"Common causes include unhealthy diet, too much salt, stress, obesity, and lack of exercise.\",\n",
        "        \"Risk factors include age, family history, smoking, alcohol use, and chronic stress.\",\n",
        "        \"Untreated high blood pressure can lead to heart disease, stroke, and kidney damage.\"\n",
        "    ]\n",
        "    trace(\"VALIDATOR_RETURN\", f\"Fallback documents count: {len(documents)}\")\n",
        "\n",
        "# =========================\n",
        "# EMBEDDINGS + VECTOR STORE\n",
        "# =========================\n",
        "trace(\"EMBEDDER\", \"Generating embeddings\")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "doc_vectors = embedder.encode(documents)\n",
        "\n",
        "if len(doc_vectors.shape) == 1:\n",
        "    doc_vectors = doc_vectors.reshape(1, -1)\n",
        "\n",
        "doc_vectors = doc_vectors.astype(\"float32\")\n",
        "trace(\"EMBEDDER_RETURN\", f\"Embedding shape: {doc_vectors.shape}\")\n",
        "\n",
        "trace(\"VECTOR_DB\", f\"Initializing FAISS with {len(documents)} documents\")\n",
        "index = faiss.IndexFlatL2(doc_vectors.shape[1])\n",
        "index.add(doc_vectors)\n",
        "\n",
        "def retrieve_internal(query, k=3):\n",
        "    qv = embedder.encode([query]).astype(\"float32\")\n",
        "    _, ids = index.search(qv, k)\n",
        "    results = [documents[i] for i in ids[0]]\n",
        "    trace(\"RETRIEVER_RETURN\", f\"Internal docs retrieved: {len(results)}\")\n",
        "    return results\n",
        "\n",
        "# =========================\n",
        "# EXTERNAL KNOWLEDGE AGENT\n",
        "# =========================\n",
        "def retrieve_external_wiki(query):\n",
        "    try:\n",
        "        titles = wikipedia.search(query)\n",
        "        trace(\"RETRIEVER_RETURN\", f\"Wikipedia titles found: {titles[:5]}\")\n",
        "        for t in titles:\n",
        "            if \"hypertension\" in t.lower():\n",
        "                summary = wikipedia.summary(t, sentences=4)\n",
        "                trace(\"RETRIEVER_RETURN\", f\"External summary length: {len(summary)}\")\n",
        "                return summary\n",
        "        return \"\"\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "# =========================\n",
        "# RELEVANCE VERIFIER\n",
        "# =========================\n",
        "def verify_relevance(text):\n",
        "    keywords = [\"blood\", \"pressure\", \"hypertension\"]\n",
        "    result = all(k in text.lower() for k in keywords)\n",
        "    trace(\"VERIFIER_RETURN\", f\"External relevance check: {result}\")\n",
        "    return result\n",
        "\n",
        "# =========================\n",
        "# LLM\n",
        "# =========================\n",
        "trace(\"LLM\", \"Loading BLOOM-560M\")\n",
        "model_name = \"bigscience/bloom-560m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=250,\n",
        "    temperature=0.6\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# RETRIEVER AGENT\n",
        "# =========================\n",
        "def retriever_agent(query):\n",
        "    trace(\"RETRIEVER\", \"Fetching internal knowledge\")\n",
        "    internal = retrieve_internal(query)\n",
        "\n",
        "    trace(\"RETRIEVER\", \"Fetching external knowledge\")\n",
        "    external = retrieve_external_wiki(query)\n",
        "\n",
        "    if not verify_relevance(external):\n",
        "        trace(\"RETRIEVER\", \"External source rejected (low relevance)\")\n",
        "        external = \"\"\n",
        "\n",
        "    trace(\"RETRIEVER_RETURN\", f\"Internal chunks: {len(internal)}, External chars: {len(external)}\")\n",
        "    return internal, external\n",
        "\n",
        "# =========================\n",
        "# GENERATOR AGENT\n",
        "# =========================\n",
        "def generator_agent(query, internal, external):\n",
        "    trace(\"GENERATOR\", \"Generating draft answer\")\n",
        "\n",
        "    context = \"\\n\".join(internal) + \"\\n\" + external\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a medical expert.\n",
        "Explain in very simple terms.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    output = llm(prompt)[0][\"generated_text\"]\n",
        "    trace(\"GENERATOR_RETURN\", f\"Draft length: {len(output)} characters\")\n",
        "    return output\n",
        "\n",
        "# =========================\n",
        "# CRITIC AGENT\n",
        "# =========================\n",
        "def critic_agent(answer):\n",
        "    trace(\"CRITIC\", \"Reviewing answer for safety and relevance\")\n",
        "\n",
        "    forbidden = [\"atrial fibrillation\", \"arrhythmia\"]\n",
        "    for f in forbidden:\n",
        "        if f in answer.lower():\n",
        "            trace(\"CRITIC_RETURN\", f\"Rejected due to keyword: {f}\")\n",
        "            return False, \"Unrelated medical condition detected\"\n",
        "\n",
        "    trace(\"CRITIC_RETURN\", \"Approved\")\n",
        "    return True, \"Answer approved\"\n",
        "\n",
        "# =========================\n",
        "# NLP SUMMARIZER\n",
        "# =========================\n",
        "def nlp_summarize(text, max_sentences=3):\n",
        "    trace(\"SUMMARIZER\", \"Condensing answer using NLP\")\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    summary = \" \".join(sentences[:max_sentences])\n",
        "    trace(\"SUMMARIZER_RETURN\", f\"Summary length: {len(summary)} characters\")\n",
        "    return summary\n",
        "\n",
        "# =========================\n",
        "# AGENTIC ORCHESTRATOR\n",
        "# =========================\n",
        "def agentic_medical_rag(query):\n",
        "    trace(\"AGENT\", \"Agent activated\")\n",
        "    trace(\"PLAN\", \"retrieve ‚Üí verify ‚Üí generate ‚Üí critique ‚Üí summarize\")\n",
        "\n",
        "    internal, external = retriever_agent(query)\n",
        "    draft = generator_agent(query, internal, external)\n",
        "\n",
        "    ok, verdict = critic_agent(draft)\n",
        "    trace(\"CRITIC\", verdict)\n",
        "\n",
        "    if not ok:\n",
        "        return \"Answer rejected by critic agent.\"\n",
        "\n",
        "    final = nlp_summarize(draft)\n",
        "    trace(\"AGENT_RETURN\", f\"Final answer length: {len(final)} characters\")\n",
        "    return final\n",
        "\n",
        "# =========================\n",
        "# RUN DEMO\n",
        "# =========================\n",
        "query = \"Explain the causes and risk factors of hypertension in simple terms.\"\n",
        "final_answer = agentic_medical_rag(query)\n",
        "\n",
        "print(\"\\n‚úÖ FINAL AGENTIC ANSWER:\\n\")\n",
        "print(final_answer)\n",
        "\n",
        "print(\"\\nüìä EXECUTION TRACE:\\n\")\n",
        "for t in TRACE_LOG:\n",
        "    print(t)"
      ],
      "metadata": {
        "id": "YagNz7P123f9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}